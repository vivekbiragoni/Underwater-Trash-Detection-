{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lzZyUCxjeajL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n 'rov': 0,\\n 'plant': 1,\\n 'animal_fish': 2,\\n 'animal_starfish': 3,\\n 'animal_shells': 4,\\n 'animal_crab': 5,\\n 'animal_eel': 6,\\n 'animal_etc': 7,\\n 'trash_etc': 8,\\n 'trash_fabric': 9,\\n 'trash_fishing_gear': 10,\\n 'trash_metal': 11,\\n 'trash_paper': 12,\\n 'trash_plastic': 13,\\n 'trash_rubber': 14,\\n 'trash_wood': 15\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Going to use TrashCAN 1.0 Dataset (https://conservancy.umn.edu/handle/11299/214865)\n",
    "# Specifically, use TrashCAN-Material sub-dataset with the following classes:\n",
    "\n",
    "'''\n",
    " 'rov': 0,\n",
    " 'plant': 1,\n",
    " 'animal_fish': 2,\n",
    " 'animal_starfish': 3,\n",
    " 'animal_shells': 4,\n",
    " 'animal_crab': 5,\n",
    " 'animal_eel': 6,\n",
    " 'animal_etc': 7,\n",
    " 'trash_etc': 8,\n",
    " 'trash_fabric': 9,\n",
    " 'trash_fishing_gear': 10,\n",
    " 'trash_metal': 11,\n",
    " 'trash_paper': 12,\n",
    " 'trash_plastic': 13,\n",
    " 'trash_rubber': 14,\n",
    " 'trash_wood': 15\n",
    "'''\n",
    "\n",
    "# Reference paper: https://arxiv.org/pdf/2007.08097.pdf\n",
    "\n",
    "# This dataset includes both detection and segmentation labels (going to just focus on detection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXr_bnA0Dzaa"
   },
   "source": [
    "##**Setup of Environment and Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SuTXP1jtFU0w"
   },
   "outputs": [],
   "source": [
    "# for debugging\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Sxw6OgTXLYCO"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import pycocotools\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "# pickle compatibility:\n",
    "# because lower pandas version used in colab, make sure pickle files are protocol = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6spr8Eo8K8cb"
   },
   "outputs": [],
   "source": [
    "#os.chdir('/content/gdrive/MyDrive/UTD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9jLeLHW5Lvd6"
   },
   "outputs": [],
   "source": [
    "# define the torchvision image transforms\n",
    "# here just the basic transform which converts an input image to a tensor\n",
    "# later, can include data augmentation here, like transforms.RandomHorizontalFlip(0.5) (just add to the list)\n",
    "# note that data augmentation will only be performed on training data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Jczvvkb1LbnL"
   },
   "outputs": [],
   "source": [
    "# construct Dataset class for pytorch\n",
    "\n",
    "class UnderwaterTrashDataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Pytorch Dataset class for Underwater Trash Dataset (Trash_CAN 1.0)\n",
    "    \n",
    "    data_file_path := path to pickle file containing dataset (annotations and filenames to images)\n",
    "    images_path := path to folder containing actual image files\n",
    "    transforms := data transformation and augmentation\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data_file_path, images_path, transforms=None):\n",
    "        if data_file_path:\n",
    "            self.data = pd.read_pickle(data_file_path)\n",
    "            self.classes = self.data.category_id.unique()\n",
    "        self.images_path = images_path\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        temp = self.data[self.data.image_id == idx]\n",
    "        \n",
    "        image = Image.open(os.path.join(self.images_path, temp.file_name.iloc[0])).convert(\"RGB\")\n",
    "        \n",
    "        box_list = copy.deepcopy(list(temp.bbox))\n",
    "\n",
    "        for box in box_list: # xmax = xmin + width, ymax = ymin + height\n",
    "            box[2] = box[2] + box[0]\n",
    "            box[3] = box[3] + box[1]\n",
    "        \n",
    "        box_list = torch.as_tensor(box_list, dtype=torch.float32)\n",
    "        \n",
    "        labels = torch.as_tensor(temp.category_id.values - 1, dtype=torch.int64)\n",
    "        # labels = torch.as_tensor(temp.category_id.values, dtype=torch.int64)\n",
    "        \n",
    "        image_id = torch.tensor([idx])\n",
    "        \n",
    "        area = (box_list[:, 3] - box_list[:, 1]) * (box_list[:, 2] - box_list[:,0])\n",
    "        \n",
    "        iscrowd = torch.zeros((len(box_list),), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = box_list\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        return image, target\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.image_id.nunique()\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "65IJjANDLkIi"
   },
   "outputs": [],
   "source": [
    "# instantiate datasets\n",
    "\n",
    "train = UnderwaterTrashDataset('UTD_train.pkl', 'dataset/material_version/train/', transforms=transform)\n",
    "val = UnderwaterTrashDataset('UTD_val.pkl', 'dataset/material_version/val/', transforms=transform)\n",
    "test = UnderwaterTrashDataset('UTD_test.pkl', 'dataset/material_version/test/', transforms=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9COd3K291hE",
    "outputId": "c0e410ee-acaa-44c1-eb9a-6cd7ff84a4b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0118, 0.0118, 0.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
       "          [0.0235, 0.0235, 0.0235,  ..., 0.0275, 0.0275, 0.0275]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
       " {'boxes': tensor([[  1.0020, 171.0020, 477.9980, 316.9980],\n",
       "          [233.0083, 252.0040, 271.9950, 282.9960],\n",
       "          [270.0312, 246.0034, 309.9933, 275.9933],\n",
       "          [  5.0045, 238.0041,  39.9839, 263.9688]]),\n",
       "  'labels': tensor([1, 3, 3, 3]),\n",
       "  'image_id': tensor([1]),\n",
       "  'area': tensor([69639.5625,  1208.2725,  1198.4541,   908.2279]),\n",
       "  'iscrowd': tensor([0, 0, 0, 0])})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "drLARkAlbfB3"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_FwFfGyedfbz"
   },
   "outputs": [],
   "source": [
    "# loads in the model and adjusts the last layer to output the correct number of classes\n",
    "# change this later\n",
    "\n",
    "def get_model(num_classes):\n",
    "   # load an object detection model pre-trained on COCO\n",
    "   model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "   # get the number of input features for the classifier\n",
    "   in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "   # replace the pre-trained head with a new one\n",
    "   model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "   \n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UmRkOhy7gUWX"
   },
   "outputs": [],
   "source": [
    "# need to copy training reference file from torch repo:\n",
    "# os.mkdir('/content/gdrive/MyDrive/torch_training_ref')\n",
    "#os.chdir('/content/gdrive/MyDrive/torch_training_ref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OunRRLa6ggQ0",
    "outputId": "46d56124-9261-4011-f57d-ca98ae9deaf9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'vision'...\n",
      "fetch-pack: unexpected disconnect while reading sideband packet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git clone https://github.com/pytorch/vision.git\n",
    "cd vision\n",
    "cp references/detection/utils.py ../\n",
    "cp references/detection/transforms.py ../\n",
    "cp references/detection/coco_eval.py ../\n",
    "cp references/detection/engine.py ../\n",
    "cp references/detection/coco_utils.py ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "whGwr6dbT0DC"
   },
   "outputs": [],
   "source": [
    "# define training and validation data loaders\n",
    "data_loader_train = torch.utils.data.DataLoader(train, batch_size=8, \n",
    "                                                shuffle=True, num_workers=2,\n",
    "                                                collate_fn=collate_fn)\n",
    "\n",
    "data_loader_val = torch.utils.data.DataLoader(val, batch_size=8,\n",
    "                                              shuffle=False, num_workers=2,\n",
    "                                              collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq784xiRDuLS"
   },
   "source": [
    "##**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSC6_0_NY5vv",
    "outputId": "c30d069b-868c-4c79-867b-336b2fb1670f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() # check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "txyOSJLvcPU-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /Users/aryanodugoudar/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     h\u001b[39m.\u001b[39;49mrequest(req\u001b[39m.\u001b[39;49mget_method(), req\u001b[39m.\u001b[39;49mselector, req\u001b[39m.\u001b[39;49mdata, headers,\n\u001b[1;32m   1349\u001b[0m               encode_chunked\u001b[39m=\u001b[39;49mreq\u001b[39m.\u001b[39;49mhas_header(\u001b[39m'\u001b[39;49m\u001b[39mTransfer-encoding\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m   1350\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1328\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders(body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1277\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1037\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m \n\u001b[1;32m   1041\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 975\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    976\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1454\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1452\u001b[0m     server_hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[0;32m-> 1454\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context\u001b[39m.\u001b[39;49mwrap_socket(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msock,\n\u001b[1;32m   1455\u001b[0m                                       server_hostname\u001b[39m=\u001b[39;49mserver_hostname)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:513\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    508\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    509\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    510\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    511\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[1;32m    514\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[1;32m    515\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[1;32m    516\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[1;32m    517\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[1;32m    518\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[1;32m    519\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    520\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[1;32m    521\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1071\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1071\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   1072\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1342\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1342\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[1;32m   1343\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m num_classes \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[39m# get the model using our helper function\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[39m=\u001b[39m get_model(num_classes)\n\u001b[1;32m     11\u001b[0m \u001b[39m# move model to the right device\u001b[39;00m\n\u001b[1;32m     12\u001b[0m model\u001b[39m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(num_classes)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_model\u001b[39m(num_classes):\n\u001b[1;32m      5\u001b[0m    \u001b[39m# load an object detection model pre-trained on COCO\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m    model \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mdetection\u001b[39m.\u001b[39;49mfasterrcnn_resnet50_fpn(pretrained\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      8\u001b[0m    \u001b[39m# get the number of input features for the classifier\u001b[39;00m\n\u001b[1;32m      9\u001b[0m    in_features \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mroi_heads\u001b[39m.\u001b[39mbox_predictor\u001b[39m.\u001b[39mcls_score\u001b[39m.\u001b[39min_features\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:142\u001b[0m, in \u001b[0;36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    136\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsing \u001b[39m\u001b[39m{\u001b[39;00msequence_to_str(\u001b[39mtuple\u001b[39m(keyword_only_kwargs\u001b[39m.\u001b[39mkeys()), separate_last\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mand \u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m as positional \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minstead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate(keyword_only_kwargs)\n\u001b[0;32m--> 142\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_utils.py:228\u001b[0m, in \u001b[0;36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[1;32m    226\u001b[0m     kwargs[weights_param] \u001b[39m=\u001b[39m default_weights_arg\n\u001b[0;32m--> 228\u001b[0m \u001b[39mreturn\u001b[39;00m builder(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/detection/faster_rcnn.py:566\u001b[0m, in \u001b[0;36mfasterrcnn_resnet50_fpn\u001b[0;34m(weights, progress, num_classes, weights_backbone, trainable_backbone_layers, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m model \u001b[39m=\u001b[39m FasterRCNN(backbone, num_classes\u001b[39m=\u001b[39mnum_classes, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    565\u001b[0m \u001b[39mif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(weights\u001b[39m.\u001b[39;49mget_state_dict(progress\u001b[39m=\u001b[39;49mprogress))\n\u001b[1;32m    567\u001b[0m     \u001b[39mif\u001b[39;00m weights \u001b[39m==\u001b[39m FasterRCNN_ResNet50_FPN_Weights\u001b[39m.\u001b[39mCOCO_V1:\n\u001b[1;32m    568\u001b[0m         overwrite_eps(model, \u001b[39m0.0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/_api.py:66\u001b[0m, in \u001b[0;36mWeightsEnum.get_state_dict\u001b[0;34m(self, progress)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_dict\u001b[39m(\u001b[39mself\u001b[39m, progress: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Mapping[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m load_state_dict_from_url(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl, progress\u001b[39m=\u001b[39;49mprogress)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/hub.py:731\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[1;32m    729\u001b[0m         r \u001b[39m=\u001b[39m HASH_REGEX\u001b[39m.\u001b[39msearch(filename)  \u001b[39m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[1;32m    730\u001b[0m         hash_prefix \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m r \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 731\u001b[0m     download_url_to_file(url, cached_file, hash_prefix, progress\u001b[39m=\u001b[39;49mprogress)\n\u001b[1;32m    733\u001b[0m \u001b[39mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[1;32m    734\u001b[0m     \u001b[39mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/hub.py:597\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    595\u001b[0m file_size \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    596\u001b[0m req \u001b[39m=\u001b[39m Request(url, headers\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mtorch.hub\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[0;32m--> 597\u001b[0m u \u001b[39m=\u001b[39m urlopen(req)\n\u001b[1;32m    598\u001b[0m meta \u001b[39m=\u001b[39m u\u001b[39m.\u001b[39minfo()\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(meta, \u001b[39m'\u001b[39m\u001b[39mgetheaders\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(req, data)\n\u001b[1;32m    521\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_open, protocol, protocol \u001b[39m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m                           \u001b[39m'\u001b[39;49m\u001b[39m_open\u001b[39;49m\u001b[39m'\u001b[39;49m, req)\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_open(http\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mHTTPSConnection, req,\n\u001b[1;32m   1392\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_context, check_hostname\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_hostname)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         h\u001b[39m.\u001b[39mrequest(req\u001b[39m.\u001b[39mget_method(), req\u001b[39m.\u001b[39mselector, req\u001b[39m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[39m=\u001b[39mreq\u001b[39m.\u001b[39mhas_header(\u001b[39m'\u001b[39m\u001b[39mTransfer-encoding\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m     r \u001b[39m=\u001b[39m h\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)>"
     ]
    }
   ],
   "source": [
    "# change these hyperparams later\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has 16 classes (see list above)\n",
    "num_classes = 16\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_model(num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.002,\n",
    "                            momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by # 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PTsh131FY513",
    "outputId": "5e1235e7-746a-4fd7-f52a-05b9f6ea5b69"
   },
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "# let's train it for 10 epochs\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "   # train for one epoch, printing every 10 iterations\n",
    "   train_one_epoch(model, optimizer, data_loader_train, device, epoch, print_freq=10)\n",
    "   \n",
    "   # update the learning rate\n",
    "   lr_scheduler.step()\n",
    "   # evaluate on the test dataset\n",
    "   evaluate(model, data_loader_val, device=device)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBKzMUA5DdvM"
   },
   "source": [
    "##**Running Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QGWcFdFwL1l5"
   },
   "outputs": [],
   "source": [
    "os.mkdir(\"/content/gdrive/MyDrive/UTD/fasterRCNN_results\")\n",
    "torch.save(model.state_dict(), \"/content/gdrive/MyDrive/UTD/fasterRCNN_results/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w86bdXU3L123",
    "outputId": "d3df936b-dabf-41be-b652-d2254f72084a"
   },
   "outputs": [],
   "source": [
    "loaded_model = get_model(num_classes = 16)\n",
    "loaded_model.load_state_dict(torch.load('/content/gdrive/MyDrive/UTD/fasterRCNN_results/model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "id": "oQQEKg079zfS",
    "outputId": "1e988c8d-c291-427f-9e29-c2a62d2119eb"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle('/content/gdrive/MyDrive/UTD/UTD_test.pkl')\n",
    "files = ['vid_000077_frame0000020.jpg', 'vid_000090_frame0000051.jpg', 'vid_000106_frame0000027.jpg']\n",
    "i = 0\n",
    "\n",
    "for im_file in files:\n",
    "  temp = test_df[test_df.file_name == im_file]\n",
    "  idx = temp.image_id.values[0]\n",
    "  labels = list(temp.category_id.values)\n",
    "  img, _ = test[idx]\n",
    "  label_boxes = np.array(test[idx][1][\"boxes\"])\n",
    "\n",
    "  loaded_model.eval()\n",
    "  with torch.no_grad():\n",
    "    prediction = loaded_model([img])\n",
    "  image = Image.fromarray(img.mul(255).permute(1, 2,0).byte().numpy())\n",
    "  draw = ImageDraw.Draw(image)\n",
    "\n",
    "  # draw groundtruth\n",
    "  for elem in range(len(label_boxes)):\n",
    "    draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]),\n",
    "    (label_boxes[elem][2], label_boxes[elem][3])], \n",
    "    outline =\"green\", width =3)\n",
    "\n",
    "  # draw predictions\n",
    "  for element in range(len(prediction[0][\"boxes\"])):\n",
    "    boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "    score = np.round(prediction[0][\"scores\"][element].cpu().numpy(), decimals= 4)\n",
    "    if score > 0.5:\n",
    "        draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], \n",
    "        outline =\"yellow\", width =3)\n",
    "        draw.text((boxes[0], boxes[1]), text = str(score))\n",
    "        draw.text((boxes[0], boxes[1]), text = str(labels[element]))\n",
    "  plt.figure(i)\n",
    "  plt.imshow(image)\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ucTujzsyAqZY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "UTD_FasterRCNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
