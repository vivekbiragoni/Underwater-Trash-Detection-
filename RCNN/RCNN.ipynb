{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = 'path/to/images'\n",
    "ANNOTATION_DIR = 'path/to/annotations'\n",
    "LABEL_MAP_FILE = 'path/to/label_map.pbtxt'\n",
    "OUTPUT_DIR = 'path/to/output'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "label_map = label_map_util.load_labelmap(LABEL_MAP_FILE)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "def create_model(num_classes):\n",
    "    base_model = tf.keras.applications.InceptionResNetV2(include_top=False, weights='imagenet')\n",
    "\n",
    "    feature_map = base_model.output\n",
    "\n",
    "    rpn = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='rpn_conv')(feature_map)\n",
    "\n",
    "    rpn_class = tf.keras.layers.Conv2D(2, (1, 1), activation='softmax', name='rpn_class')(rpn)\n",
    "\n",
    "    rpn_bbox = tf.keras.layers.Conv2D(4, (1, 1), activation='linear', name='rpn_bbox')(rpn)\n",
    "\n",
    "    proposals = tf.keras.layers.ProposalLayer()([rpn_class, rpn_bbox])\n",
    "\n",
    "    rois = tf.keras.layers.ROIAlign((7, 7), 1)([proposals, feature_map])\n",
    "\n",
    "    fc1 = tf.keras.layers.Dense(1024, activation='relu')(tf.keras.layers.Flatten()(rois))\n",
    "\n",
    "    class_logits = tf.keras.layers.Dense(num_classes, name='class_logits')(fc1)\n",
    "\n",
    "    bboxes = tf.keras.layers.Dense(num_classes * 4, activation='linear', name='bboxes')(fc1)\n",
    "\n",
    "    model = tf.keras.Model(inputs=base_model.input, outputs=[class_logits, bboxes])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(NUM_CLASSES)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.001, momentum=0.9), loss=[tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), tf.keras.losses.Huber()], metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "return image\n",
    "\n",
    "def load_annotations(annotation_path):\n",
    "tree = ET.parse(annotation_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "bboxes = []\n",
    "labels = []\n",
    "\n",
    "for obj in root.findall('object'):\n",
    "    label = obj.find('name').text\n",
    "    bbox = obj.find('bndbox')\n",
    "    xmin = int(bbox.find('xmin').text)\n",
    "    ymin = int(bbox.find('ymin').text)\n",
    "    xmax = int(bbox.find('xmax').text)\n",
    "    ymax = int(bbox.find('ymax').text)\n",
    "\n",
    "    bboxes.append([ymin, xmin, ymax, xmax])\n",
    "    labels.append(label)\n",
    "\n",
    "return np.array(bboxes), np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_tfrecord(output_file, image_dir, annotation_dir, label_map, category_index):\n",
    "    writer = tf.io.TFRecordWriter(output_file)\n",
    "\n",
    "    for idx, image_file in enumerate(os.listdir(image_dir)):\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        annotation_path = os.path.join(annotation_dir, os.path.splitext(image_file)[0] + '.xml')\n",
    "\n",
    "        image = load_image(image_path)\n",
    "        bboxes, labels = load_annotations(annotation_path)\n",
    "\n",
    "        encoded_image_data = tf.io.encode_jpeg(image)\n",
    "\n",
    "        feature_dict = {\n",
    "            'image/height': dataset_util.int64_feature(image.shape[0]),\n",
    "            'image/width': dataset_util.int64_feature(image.shape[1]),\n",
    "            'image/filename': dataset_util.bytes_feature(image_file.encode('utf8')),\n",
    "            'image/source_id': dataset_util.bytes_feature(image_file.encode('utf8')),\n",
    "            'image/encoded': dataset_util.bytes_feature(encoded_image_data.numpy()),\n",
    "            'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "            'image/object/bbox/xmin': dataset_util.float_list_feature(bboxes[:, 1] / image.shape[1]),\n",
    "            'image/object/bbox/xmax': dataset_util.float_list_feature(bboxes[:, 3] / image.shape[1]),\n",
    "            'image/object/bbox/ymin': dataset_util.float_list_feature(bboxes[:, 0] / image.shape[0]),\n",
    "            'image/object/bbox/ymax': dataset_util.float_list_feature(bboxes[:, 2] / image.shape[0]),\n",
    "            'image/object/class/text': dataset_util.bytes_list_feature(labels),\n",
    "            'image/object/class/label': dataset_util.int64_list_feature([category_index[label]['id'] for label in labels]),\n",
    "        }\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tfrecord(os.path.join(OUTPUT_DIR, 'train.tfrecord'), IMAGE_DIR, ANNOTATION_DIR, label_map, category_index)\n",
    "train_dataset = tf.data.TFRecordDataset(os.path.join(OUTPUT_DIR, 'train.tfrecord'))\n",
    "train_dataset = train_dataset.map(lambda x: dataset_util.parse_single_example(x, {'image/encoded': tf.io.FixedLenFeature([], tf.string), 'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32), 'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32), 'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32), 'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32), 'image/object/class/text': tf.io.VarLenFeature(tf.string)}))\n",
    "train_dataset = train_dataset.map(lambda x: (tf.io.decode_jtrain_dataset = train_dataset.map(lambda x: (tf.io.decode_jpeg(x['image/encoded'], channels=3), tf.sparse.to_dense(x['image/object/bbox/xmin']), tf.sparse.to_dense(x['image/object/bbox/ymin']), tf.sparse.to_dense(x['image/object/bbox/xmax']), tf.sparse.to_dense(x['image/object/bbox/ymax']), x['image/object/class/text']))\n",
    "train_dataset = train_dataset.map(lambda image, xmin, ymin, xmax, ymax, class_text: (image, {'bbox': tf.stack([ymin, xmin, ymax, xmax], axis=-1), 'class_text': tf.sparse.to_dense(class_text)}))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "model = create_model(num_classes=len(label_map))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=object_detection.losses.WeightedSigmoidFocal(num_classes=len(label_map)))\n",
    "\n",
    "callbacks = [\n",
    "tf.keras.callbacks.ModelCheckpoint(os.path.join(CHECKPOINT_DIR, 'rcnn_{epoch:02d}.h5')),\n",
    "tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR),\n",
    "tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE),\n",
    "]\n",
    "\n",
    "model.fit(train_dataset, epochs=EPOCHS, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(image_path, model, category_index):\n",
    "    image = load_image(image_path)\n",
    "\n",
    "    boxes, scores, classes, _ = model.predict(np.expand_dims(image, axis=0))\n",
    "\n",
    "    boxes = boxes[0]\n",
    "    scores = scores[0]\n",
    "    classes = classes[0]\n",
    "\n",
    "    detections = []\n",
    "\n",
    "    for box, score, cls in zip(boxes, scores, classes):\n",
    "        if score > CONFIDENCE_THRESHOLD:\n",
    "            ymin, xmin, ymax, xmax = box\n",
    "            label = category_index[cls]['name']\n",
    "            detections.append({'label': label, 'score': score, 'box': [xmin, ymin, xmax, ymax]})\n",
    "\n",
    "    return detections\n",
    "\n",
    "for image_file in os.listdir(NEW_IMAGE_DIR):\n",
    "    image_path = os.path.join(NEW_IMAGE_DIR, image_file)\n",
    "    detections = predict(image_path, model, category_index)\n",
    "\n",
    "    image = load_image(image_path)\n",
    "\n",
    "    for detection in detections:\n",
    "        label = detection['label']\n",
    "        score = detection['score']\n",
    "        box = detection['box']\n",
    "\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "\n",
    "        cv2.rectangle(image, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2)\n",
    "        cv2.putText(image, '{}: {:.2f}'.format(label, score), (int(xmin), int(ymin)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow('image', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #alternate\n",
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import tensorflow as tf\n",
    "# from object_detection.utils import visualization_utils as viz_utils\n",
    "# from object_detection.utils import label_map_util\n",
    "# from object_detection.builders import model_builder\n",
    "\n",
    "# IMAGE_DIR = '/path/to/image/directory'\n",
    "# ANNOTATION_PATH = '/path/to/annotation/file'\n",
    "# CHECKPOINT_PATH = '/path/to/checkpoint'\n",
    "# LABEL_MAP_PATH = '/path/to/label/map'\n",
    "# CONFIDENCE_THRESHOLD = 0.5\n",
    "\n",
    "# # Load the label map\n",
    "# label_map = label_map_util.load_labelmap(LABEL_MAP_PATH)\n",
    "# categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=2, use_display_name=True)\n",
    "# category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "# # Load the model\n",
    "# pipeline_config = model_builder.create_pipeline_proto_from_configs_file(os.path.join(CHECKPOINT_PATH, 'pipeline.config'))\n",
    "# model_config = pipeline_config.model\n",
    "# detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# # Restore checkpoint\n",
    "# ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "# ckpt.restore(os.path.join(CHECKPOINT_PATH, 'checkpoint', 'ckpt-0')).expect_partial()\n",
    "\n",
    "# @tf.function\n",
    "# def detect_fn(image):\n",
    "#     image, shapes = detection_model.preprocess(image)\n",
    "#     prediction_dict = detection_model.predict(image, shapes)\n",
    "#     detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "#     return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
    "\n",
    "# def detect(image_path):\n",
    "#     image_np = cv2.imread(image_path)\n",
    "#     input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "#     detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "\n",
    "#     label_id_offset = 1\n",
    "#     image_np_with_detections = image_np.copy()\n",
    "\n",
    "#     viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "#           image_np_with_detections,\n",
    "#           detections['detection_boxes'][0].numpy(),\n",
    "#           (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "#           detections['detection_scores'][0].numpy(),\n",
    "#           category_index,\n",
    "#           use_normalized_coordinates=True,\n",
    "#           max_boxes_to_draw=200,\n",
    "#           min_score_thresh=CONFIDENCE_THRESHOLD,\n",
    "#           agnostic_mode=False)\n",
    "\n",
    "#     return image_np_with_detections\n",
    "\n",
    "# # Test the model on a single image\n",
    "# image_file = 'image.jpg'\n",
    "# image_path = os.path.join(IMAGE_DIR, image_file)\n",
    "# output_image = detect(image_path)\n",
    "\n",
    "# # Display the image\n",
    "# cv2.imshow('Output', output_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (v3.9.12:b28265d7e6, Mar 23 2022, 18:22:40) \n[Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
